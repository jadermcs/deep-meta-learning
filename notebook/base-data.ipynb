{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exotic-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from fastprogress.fastprogress import master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "frank-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-queue",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- shuffle columns except class\n",
    "- save dataframes with {name}\\_{mean_score}\\_{std_score}.csv\n",
    "- initially test only on classical suite than extend to all classification datasets\n",
    "- implement selfsupervised as in [TabNet](https://arxiv.org/pdf/1908.07442.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chemical-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "count = 0\n",
    "\n",
    "os.makedirs('../samples', exist_ok=True)\n",
    "\n",
    "clf1 = RandomForestClassifier(random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "oriental-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "openml_list = openml.datasets.list_datasets()\n",
    "suites = openml.study.list_suites(output_format=\"dataframe\", status=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "competent-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>alias</th>\n",
       "      <th>main_entity_type</th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>creator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>OpenML100</td>\n",
       "      <td>task</td>\n",
       "      <td>Collaborative, reproducible benchmarking and a...</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2019-02-21 18:40:13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>OpenML-CC18</td>\n",
       "      <td>task</td>\n",
       "      <td>OpenML Benchmarking Suites and the OpenML-CC18</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2019-02-21 18:47:13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>216</td>\n",
       "      <td>CoolStudy</td>\n",
       "      <td>task</td>\n",
       "      <td>A Cool Study with an Awesome name</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2019-02-28 23:00:26</td>\n",
       "      <td>8006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>217</td>\n",
       "      <td>Study</td>\n",
       "      <td>task</td>\n",
       "      <td>A Cool Study with an Awesome name</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2019-02-28 23:05:11</td>\n",
       "      <td>8006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>AutoML-Benchmark</td>\n",
       "      <td>task</td>\n",
       "      <td>AutoML Benchmark</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2019-05-02 13:35:08</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>FOREX</td>\n",
       "      <td>task</td>\n",
       "      <td>Forex</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2019-06-04 00:45:17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>225</td>\n",
       "      <td>OpenML-friendly</td>\n",
       "      <td>task</td>\n",
       "      <td>OpenML100-friendly</td>\n",
       "      <td>active</td>\n",
       "      <td>2019-09-16 19:41:46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>236</td>\n",
       "      <td>a9ee1f0b2a4b48b6b6da1653fe92890e</td>\n",
       "      <td>task</td>\n",
       "      <td>Item Response Theory for Classification problems</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-04-06 21:38:55</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>239</td>\n",
       "      <td>c638a5d3d31241179f9b4853951fdb79</td>\n",
       "      <td>task</td>\n",
       "      <td>Item Response Theory for Regression problems</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-04-19 22:15:30</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>240</td>\n",
       "      <td>e5e7f56c8655433eb2418c240ec8b8c0</td>\n",
       "      <td>task</td>\n",
       "      <td>InvestigatingDL</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-04-28 02:30:38</td>\n",
       "      <td>2902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>242</td>\n",
       "      <td>aece328c3ee64b4d8e0c7271a6f9efa3</td>\n",
       "      <td>task</td>\n",
       "      <td>na</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-06-30 19:47:50</td>\n",
       "      <td>9186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>253</td>\n",
       "      <td>testecc18</td>\n",
       "      <td>task</td>\n",
       "      <td>TesteCC18</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-09-01 00:57:54</td>\n",
       "      <td>8598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>task</td>\n",
       "      <td>CC18NewBenchmark</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-09-30 08:30:00</td>\n",
       "      <td>8598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>task</td>\n",
       "      <td>Suite</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-09-30 18:45:44</td>\n",
       "      <td>3821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>task</td>\n",
       "      <td>Suite</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-10-01 01:30:19</td>\n",
       "      <td>3821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>task</td>\n",
       "      <td>Suite</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-10-01 01:32:25</td>\n",
       "      <td>3821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>task</td>\n",
       "      <td>Suite</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-10-01 18:08:14</td>\n",
       "      <td>3821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>task</td>\n",
       "      <td>Suite</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-10-01 23:27:57</td>\n",
       "      <td>3821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>task</td>\n",
       "      <td>New benchmark</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-10-06 17:40:23</td>\n",
       "      <td>8598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>269</td>\n",
       "      <td>amlb-regression</td>\n",
       "      <td>task</td>\n",
       "      <td>AutoML Benchmark Regression</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-11-19 18:28:48</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>270</td>\n",
       "      <td>amlb-classification-more</td>\n",
       "      <td>task</td>\n",
       "      <td>AutoML Benchmark More Classification</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-11-19 20:40:18</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>271</td>\n",
       "      <td>amlb-classification-all</td>\n",
       "      <td>task</td>\n",
       "      <td>AutoML Benchmark All Classification</td>\n",
       "      <td>in_preparation</td>\n",
       "      <td>2020-11-19 20:52:19</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                             alias main_entity_type  \\\n",
       "14    14                         OpenML100             task   \n",
       "99    99                       OpenML-CC18             task   \n",
       "216  216                         CoolStudy             task   \n",
       "217  217                             Study             task   \n",
       "218  218                  AutoML-Benchmark             task   \n",
       "219  219                             FOREX             task   \n",
       "225  225                   OpenML-friendly             task   \n",
       "236  236  a9ee1f0b2a4b48b6b6da1653fe92890e             task   \n",
       "239  239  c638a5d3d31241179f9b4853951fdb79             task   \n",
       "240  240  e5e7f56c8655433eb2418c240ec8b8c0             task   \n",
       "242  242  aece328c3ee64b4d8e0c7271a6f9efa3             task   \n",
       "253  253                         testecc18             task   \n",
       "258  258                               NaN             task   \n",
       "260  260                               NaN             task   \n",
       "261  261                               NaN             task   \n",
       "262  262                               NaN             task   \n",
       "263  263                               NaN             task   \n",
       "264  264                               NaN             task   \n",
       "268  268                               NaN             task   \n",
       "269  269                   amlb-regression             task   \n",
       "270  270          amlb-classification-more             task   \n",
       "271  271           amlb-classification-all             task   \n",
       "\n",
       "                                                  name          status  \\\n",
       "14   Collaborative, reproducible benchmarking and a...  in_preparation   \n",
       "99      OpenML Benchmarking Suites and the OpenML-CC18  in_preparation   \n",
       "216                  A Cool Study with an Awesome name  in_preparation   \n",
       "217                  A Cool Study with an Awesome name  in_preparation   \n",
       "218                                   AutoML Benchmark  in_preparation   \n",
       "219                                              Forex  in_preparation   \n",
       "225                                 OpenML100-friendly          active   \n",
       "236   Item Response Theory for Classification problems  in_preparation   \n",
       "239       Item Response Theory for Regression problems  in_preparation   \n",
       "240                                    InvestigatingDL  in_preparation   \n",
       "242                                                 na  in_preparation   \n",
       "253                                          TesteCC18  in_preparation   \n",
       "258                                   CC18NewBenchmark  in_preparation   \n",
       "260                                              Suite  in_preparation   \n",
       "261                                              Suite  in_preparation   \n",
       "262                                              Suite  in_preparation   \n",
       "263                                              Suite  in_preparation   \n",
       "264                                              Suite  in_preparation   \n",
       "268                                      New benchmark  in_preparation   \n",
       "269                        AutoML Benchmark Regression  in_preparation   \n",
       "270               AutoML Benchmark More Classification  in_preparation   \n",
       "271                AutoML Benchmark All Classification  in_preparation   \n",
       "\n",
       "           creation_date  creator  \n",
       "14   2019-02-21 18:40:13        1  \n",
       "99   2019-02-21 18:47:13        1  \n",
       "216  2019-02-28 23:00:26     8006  \n",
       "217  2019-02-28 23:05:11     8006  \n",
       "218  2019-05-02 13:35:08      869  \n",
       "219  2019-06-04 00:45:17        1  \n",
       "225  2019-09-16 19:41:46        1  \n",
       "236  2020-04-06 21:38:55       64  \n",
       "239  2020-04-19 22:15:30       64  \n",
       "240  2020-04-28 02:30:38     2902  \n",
       "242  2020-06-30 19:47:50     9186  \n",
       "253  2020-09-01 00:57:54     8598  \n",
       "258  2020-09-30 08:30:00     8598  \n",
       "260  2020-09-30 18:45:44     3821  \n",
       "261  2020-10-01 01:30:19     3821  \n",
       "262  2020-10-01 01:32:25     3821  \n",
       "263  2020-10-01 18:08:14     3821  \n",
       "264  2020-10-01 23:27:57     3821  \n",
       "268  2020-10-06 17:40:23     8598  \n",
       "269  2020-11-19 18:28:48      869  \n",
       "270  2020-11-19 20:40:18      869  \n",
       "271  2020-11-19 20:52:19      869  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suites.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "noble-blend",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenML Benchmark Suite\n",
      "======================\n",
      "ID..............: 271\n",
      "Name............: AutoML Benchmark All Classification\n",
      "Status..........: in_preparation\n",
      "Main Entity Type: task\n",
      "Study URL.......: https://www.openml.org/s/271\n",
      "# of Data.......: 71\n",
      "# of Tasks......: 71\n",
      "Creator.........: https://www.openml.org/u/869\n",
      "Upload Time.....: 2020-11-19 20:52:19\n"
     ]
    }
   ],
   "source": [
    "suite = openml.study.get_suite(271)\n",
    "print(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "occasional-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = suite.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "binary-prince",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      5.66% [3/53 00:54<15:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataset id 1487, ozone-level-8hr...\n",
      "Getting dataset id 54, vehicle...\n",
      "Getting dataset id 41144, madeline...\n"
     ]
    },
    {
     "ename": "OpenMLServerException",
     "evalue": "https://www.openml.org/api/v1/xml/data/qualities/41145 returned code 107: Database connection error. Usually due to high server load. Please wait for N seconds and try again. - None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/openml/datasets/functions.py\u001b[0m in \u001b[0;36m_get_dataset_qualities\u001b[0;34m(did_cache_dir, dataset_id)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqualities_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m             \u001b[0mqualities_xml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jader/.openml/cache/org/openml/www/datasets/41145/qualities.xml'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOpenMLServerException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-75e022626062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Getting dataset id {idd}, {dataset.name}...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     X, y, categorical_indicator, attribute_names = dataset.get_data(\n\u001b[1;32m      5\u001b[0m         \u001b[0mdataset_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"array\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_target_attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/openml/datasets/functions.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(dataset_id, download_data, version, error_if_multiple, cache_format)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOpenMLPrivateDatasetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremove_dataset_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/openml/datasets/functions.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(dataset_id, download_data, version, error_if_multiple, cache_format)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0mqualities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_dataset_qualities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdid_cache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenMLServerException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m362\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"No qualities found - None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/openml/datasets/functions.py\u001b[0m in \u001b[0;36m_get_dataset_qualities\u001b[0;34m(did_cache_dir, dataset_id)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0murl_extension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/qualities/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0mqualities_xml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api_calls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_perform_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_extension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqualities_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/openml/_api_calls.py\u001b[0m in \u001b[0;36m_perform_api_call\u001b[0;34m(call, request_method, data, file_elements)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__read_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0m__check_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_elements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     logging.info(\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/openml/_api_calls.py\u001b[0m in \u001b[0;36m__check_response\u001b[0;34m(response, url, file_elements)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__check_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_elements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m__parse_server_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_elements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_elements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     elif (\n\u001b[1;32m    145\u001b[0m         \u001b[0;34m\"Content-Encoding\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOpenMLServerException\u001b[0m: https://www.openml.org/api/v1/xml/data/qualities/41145 returned code 107: Database connection error. Usually due to high server load. Please wait for N seconds and try again. - None"
     ]
    }
   ],
   "source": [
    "for idd in progress_bar(datasets[20:]):\n",
    "    dataset = openml.datasets.get_dataset(idd)\n",
    "    print(f'Getting dataset id {idd}, {dataset.name}...')\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        dataset_format=\"array\", target=dataset.default_target_attribute\n",
    "    )\n",
    "    df = pd.DataFrame(X, columns=attribute_names)\n",
    "    df[\"class\"] = y\n",
    "    df.to_csv(path+dataset.name+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lonely-dressing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.25% [5/400 00:06<07:56 Files]\n",
       "    </div>\n",
       "    \n",
       "Finished 1021_page-blocks.arff<p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['height', 'lenght', 'area', 'eccen', 'p_black', 'p_and', 'mean_tr',\n",
      "       'blackpix', 'blackand', 'wb_trans', 'class'],\n",
      "      dtype='object')\n",
      "Index(['oz1', 'oz2', 'oz3', 'oz4', 'oz5', 'oz6', 'oz7', 'oz8', 'oz9', 'oz10',\n",
      "       'oz11', 'oz12', 'oz13', 'oz14', 'oz15', 'oz16', 'oz17', 'oz18', 'oz19',\n",
      "       'oz20', 'oz21', 'oz22', 'oz23', 'oz24', 'oz25', 'class'],\n",
      "      dtype='object')\n",
      "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
      "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
      "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31',\n",
      "       'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41',\n",
      "       'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51',\n",
      "       'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61',\n",
      "       'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71',\n",
      "       'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81',\n",
      "       'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'class'],\n",
      "      dtype='object')\n",
      "Index(['Gender', 'Grade', 'Age', 'Race', 'Urban.Rural', 'School', 'Grades',\n",
      "       'Sports', 'Looks', 'Money', 'class'],\n",
      "      dtype='object')\n",
      "Index(['L.CORE', 'L.SURF', 'L.O2', 'L.BP', 'SURF.STBL', 'CORE.STBL', 'BP.STBL',\n",
      "       'COMFORT', 'class'],\n",
      "      dtype='object')\n",
      "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       ...\n",
      "       'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100',\n",
      "       'class'],\n",
      "      dtype='object', length=101)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"b'v3'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-013ee5792f78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../samples/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34mf'{f}_{np.mean(scores):.3f}.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    303\u001b[0m             )\n\u001b[1;32m    304\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0;32m--> 305\u001b[0;31m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/deep-meta-learning/venv/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: \"b'v3'\""
     ]
    }
   ],
   "source": [
    "mb = master_bar(os.listdir(path))\n",
    "\n",
    "for f in mb:\n",
    "    mb.main_bar.comment = f'Files'\n",
    "    data, _ = loadarff(path+f)\n",
    "    sampler = pd.DataFrame(data)\n",
    "    print(sampler.columns)\n",
    "    if sampler.shape[0] < 1000:\n",
    "        continue\n",
    "    for i in progress_bar(range(10), parent=mb):\n",
    "        df = sampler.sample(500, replace=True, random_state=seed)\n",
    "        X = df.drop([\"class\"], axis=1).astype(str)\n",
    "        y = df[\"class\"].astype(str)\n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        scores = []\n",
    "        for train_idx, test_idx in kfold.split(X, y):\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "            clf1.fit(X_train, y_train)\n",
    "            scores.append(clf1.score(X_test, y_test))\n",
    "        df.to_csv('../samples/'+f'{f}_{np.mean(scores):.3f}.csv')\n",
    "        mb.child.comment = f'Sampler'\n",
    "    mb.write(f'Finished {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "engaging-snapshot",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arff'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5c9e11c2bf9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0marff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'arff'"
     ]
    }
   ],
   "source": [
    "import arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
