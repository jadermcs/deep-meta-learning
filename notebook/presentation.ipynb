{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "selective-tomato",
   "metadata": {},
   "source": [
    "# Deep Meta-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-pencil",
   "metadata": {},
   "source": [
    "## Motivação\n",
    "\n",
    "  - Engenharia moderna de deep learning: treine a arquitetura completa em um\n",
    "    conjunto de dados gigantesco e depois faça o fine-tuning (da ultima camada)\n",
    "    para o seu conjunto de dados com menos exemplos.\n",
    "  - Estado da arte em datasets com apenas 80 exemplos.\n",
    "\n",
    "![vgg](img/vgg_architecture.png)\n",
    "\n",
    "  - Atributos feitos a mão não são tão bons quanto os descobertos por otimização ex. texto e imagem\n",
    "\n",
    "![canny](img/canny.jpeg)\n",
    "\n",
    "  - A fase de \"pré-treino\" regulariza a arquitetura para o viés adequado a\n",
    "    compreensão de imagens, necessitando apenas de uma combinação linear\n",
    "    (ultima camada) desse sub-espaço de funções para ter uma boa generalização.\n",
    "  - Do ponto de vista de aplicação ele aprende filtros/atributos bons para o problemas.\n",
    "\n",
    "![vgg](img/vgg_filters.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-sampling",
   "metadata": {},
   "source": [
    "## Limitações\n",
    "\n",
    "- Entradas tem que ser de mesmo tamanho.\n",
    "\n",
    "#### Padding\n",
    "- Sensível a permutações\n",
    "\n",
    "![padding](img/padding.png)\n",
    "\n",
    "\n",
    "#### Permutation Invariance\n",
    "[https://arxiv.org/pdf/1612.04530.pdf](https://arxiv.org/pdf/1612.04530.pdf)\n",
    "\n",
    "![padding](img/permutation_invariance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-delhi",
   "metadata": {},
   "source": [
    "#### Solução (?)\n",
    "![Transformer Architecture](img/seq2seq.png)\n",
    "\n",
    "![Word Embedding](img/word_embedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-garbage",
   "metadata": {},
   "source": [
    "**Exemplo:**\n",
    "\n",
    "\n",
    "``` python\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-operator",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Transformer Architecture\n",
    "![Transformer Architecture](img/transformer1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-waters",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Self Attention\n",
    "![Transformer Architecture](img/transformer2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-notification",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K, Q, V\n",
    "![Transformer Architecture](img/transformer3.png)\n",
    "\n",
    "![Transformer Architecture](img/transformer4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-lawyer",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### X encoded as Z\n",
    "![Transformer Architecture](img/transformer5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-child",
   "metadata": {},
   "source": [
    "### Correlation Matrix\n",
    "\n",
    "![Transformer Architecture](img/attention1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-victim",
   "metadata": {},
   "source": [
    "## Batch Generation\n",
    "\n",
    "``` python\n",
    "path = \"datasets/\"\n",
    "for f in os.listdir(path):\n",
    "    sampler = pd.read_csv(path+f).dropna() # dropar ou não?\n",
    "    if sampler.shape[0] < 1000: \n",
    "        continue\n",
    "    for i in range(100):\n",
    "        df = sampler.sample(500, replace=True, random_state=seed+i)\n",
    "        X = df.drop([\"class\"], axis=1).astype(str)\n",
    "        y = df[\"class\"].astype(str)\n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        scores = []\n",
    "        for train_idx, test_idx in kfold.split(X, y):\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "            clf1.fit(X_train, y_train)\n",
    "            scores.append(clf1.score(X_test, y_test))\n",
    "        df.to_csv('../samples/'+f'{f}_{np.mean(scores):.3f}_{i}.csv', index=False)\n",
    "        mb.child.comment = f'Sampler'\n",
    "    mb.write(f'Finished {f}')\n",
    "```\n",
    "\n",
    "## Beyonder Architecture\n",
    "\n",
    "``` python\n",
    "number_of_base_classifiers = 10\n",
    "\n",
    "inputs = layers.Input(shape=(,))\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(inputs)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(number_of_base_classifiers, activation=\"linear\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-mortgage",
   "metadata": {},
   "source": [
    "## TabNet\n",
    "\n",
    "![Transformer Architecture](img/tabnet.png)\n",
    "\n",
    "![Transformer Architecture](img/mask.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-publicity",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "\n",
    "### Architecture\n",
    "#### Positional Encoding\n",
    "- Add an increasing value for same rows\n",
    "\n",
    "#### Data Augmentation\n",
    "- Noise injection in data\n",
    "- Synthetic data\n",
    "\n",
    "### Applications\n",
    "#### Transfer Learning\n",
    "\n",
    "#### Regression\n",
    "- accuracy classifiers\n",
    "- regularization term in a base model\n",
    "\n",
    "#### Classification\n",
    "- Predict best classifier\n",
    "- Predict best kernel for SVM\n",
    "\n",
    "#### Data Imputation\n",
    "\n",
    "#### Transformer (encoded meta-features as input for a seq2seq prediction (the encode informs what hypothesis space to select))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-night",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "https://www.lesswrong.com/posts/7ny7NLqvzJt7WfeXP/acetylcholine-learning-rate-aka-plasticity\n",
    "\n",
    "why learning rate matters for different problems, an illustration with the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-ireland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
